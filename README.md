# Markov-Chains
Transition probability matrix and equilibrium equations for Markov chain
Assume the state of the weather in Sydney on any particular day can be modelled using a state space S = {1=sunny, 2=overcast, 3=wet}. Also, assume the liklihood of any state depends only on the state on the previous day. A sunny day is followed by a sunny day 60% of the time and otherwise is overcast. An overcast day is equally likely to be followed by either a sunny or a wet day. 20% of days after a wet day are also wet, but 20% are sunny.

Write a transition probability matrix for this Markov chain.
Write down equilibrium equations and solve using R. 
